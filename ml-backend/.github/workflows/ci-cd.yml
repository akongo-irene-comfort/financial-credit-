name: Backend CI/CD Pipeline (Enhanced)

on:
  push:
    branches: [ main, develop ]
    paths:
      - 'ml-backend/**'
  pull_request:
    branches: [ main ]
    paths:
      - 'ml-backend/**'

env:
  PYTHON_VERSION: '3.11'
  DOCKER_IMAGE: credit-scoring-ml-backend

jobs:
  # Job 1: Linting and Code Quality
  lint:
    name: Code Quality Check
    runs-on: ubuntu-latest
    defaults:
      run:
        working-directory: ./ml-backend
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
      
      - name: Install linting tools
        run: |
          python -m pip install --upgrade pip
          pip install flake8 black isort mypy bandit safety
      
      - name: Lint with flake8
        run: |
          flake8 app/ --count --select=E9,F63,F7,F82 --show-source --statistics
          flake8 app/ --count --exit-zero --max-complexity=10 --max-line-length=127 --statistics
      
      - name: Check code formatting with black
        run: black --check app/
      
      - name: Check import sorting with isort
        run: isort --check-only app/
      
      - name: Security scan with bandit
        run: bandit -r app/ -ll
        continue-on-error: true
      
      - name: Check dependencies with safety
        run: safety check --json || echo "Safety check completed with warnings"
        continue-on-error: true

  # Job 2: Unit Tests with Neon Database
  test:
    name: Unit Tests
    runs-on: ubuntu-latest
    needs: lint
    defaults:
      run:
        working-directory: ./ml-backend
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install pytest pytest-cov pytest-asyncio httpx
      
      - name: Setup Prisma with Neon
        env:
          DATABASE_URL: ${{ secrets.NEON_DATABASE_URL }}
        run: |
          prisma generate
          prisma db push --skip-generate --accept-data-loss
      
      - name: Run unit tests with coverage
        env:
          DATABASE_URL: ${{ secrets.NEON_DATABASE_URL }}
          PYTHONPATH: ${{ github.workspace }}/ml-backend
        run: |
          pytest tests/ --cov=app --cov-report=xml --cov-report=html --cov-report=term -v
      
      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v4
        with:
          file: ./ml-backend/coverage.xml
          flags: backend
          fail_ci_if_error: false

  # Job 3: Integration Tests
  integration-test:
    name: Integration Tests
    runs-on: ubuntu-latest
    needs: test
    defaults:
      run:
        working-directory: ./ml-backend
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install pytest pytest-asyncio httpx
      
      - name: Setup Prisma with Neon
        env:
          DATABASE_URL: ${{ secrets.NEON_DATABASE_URL }}
        run: |
          prisma generate
          prisma db push --skip-generate --accept-data-loss
      
      - name: Start FastAPI server
        env:
          DATABASE_URL: ${{ secrets.NEON_DATABASE_URL }}
          PYTHONPATH: ${{ github.workspace }}/ml-backend
        run: |
          uvicorn app.main:app --host 0.0.0.0 --port 8000 &
          sleep 15
      
      - name: Run integration tests
        env:
          DATABASE_URL: ${{ secrets.NEON_DATABASE_URL }}
          PYTHONPATH: ${{ github.workspace }}/ml-backend
        run: |
          pytest tests/integration/ --verbose
      
      - name: Test API endpoints
        run: |
          curl -f http://localhost:8000/health || exit 1
          curl -f http://localhost:8000/ || exit 1
          curl -f http://localhost:8000/metrics || echo "Metrics endpoint check"

  # Job 4: Security Scanning
  security:
    name: Security Scan
    runs-on: ubuntu-latest
    needs: lint
    steps:
      - uses: actions/checkout@v4
      
      - name: Run Trivy vulnerability scanner
        uses: aquasecurity/trivy-action@master
        with:
          scan-type: 'fs'
          scan-ref: './ml-backend'
          format: 'sarif'
          output: 'trivy-results.sarif'
      
      - name: Upload Trivy results to GitHub Security
        uses: github/codeql-action/upload-sarif@v3
        with:
          sarif_file: 'trivy-results.sarif'

  # Job 5: Build and Test Docker Image
  build:
    name: Build Docker Image
    runs-on: ubuntu-latest
    needs: [lint, test]
    defaults:
      run:
        working-directory: ./ml-backend
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3
      
      - name: Build Docker image
        run: |
          docker build -t ${{ env.DOCKER_IMAGE }}:latest .
      
      - name: Test Docker container
        env:
          DATABASE_URL: ${{ secrets.NEON_DATABASE_URL }}
        run: |
          docker run -d -p 8000:8000 --name test-container \
            -e DATABASE_URL=$DATABASE_URL \
            ${{ env.DOCKER_IMAGE }}:latest
          sleep 20
          docker logs test-container
          curl -f http://localhost:8000/health || exit 1
          docker stop test-container
      
      - name: Scan Docker image with Trivy
        uses: aquasecurity/trivy-action@master
        with:
          image-ref: '${{ env.DOCKER_IMAGE }}:latest'
          format: 'table'
          exit-code: '0'
          severity: 'CRITICAL,HIGH'
      
      - name: Login to Docker Hub
        if: github.ref == 'refs/heads/main'
        uses: docker/login-action@v3
        with:
          username: ${{ secrets.DOCKER_USERNAME }}
          password: ${{ secrets.DOCKER_PASSWORD }}
        continue-on-error: true
      
      - name: Push Docker image
        if: github.ref == 'refs/heads/main'
        run: |
          docker tag ${{ env.DOCKER_IMAGE }}:latest ${{ secrets.DOCKER_USERNAME }}/${{ env.DOCKER_IMAGE }}:${{ github.sha }}
          docker tag ${{ env.DOCKER_IMAGE }}:latest ${{ secrets.DOCKER_USERNAME }}/${{ env.DOCKER_IMAGE }}:latest
          docker push ${{ secrets.DOCKER_USERNAME }}/${{ env.DOCKER_IMAGE }}:${{ github.sha }}
          docker push ${{ secrets.DOCKER_USERNAME }}/${{ env.DOCKER_IMAGE }}:latest
        continue-on-error: true

  # Job 6: Model Validation
  model-validation:
    name: Model Performance Validation
    runs-on: ubuntu-latest
    needs: integration-test
    defaults:
      run:
        working-directory: ./ml-backend
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
      
      - name: Setup Prisma
        env:
          DATABASE_URL: ${{ secrets.NEON_DATABASE_URL }}
        run: |
          prisma generate
      
      - name: Validate model metrics
        env:
          DATABASE_URL: ${{ secrets.NEON_DATABASE_URL }}
          PYTHONPATH: ${{ github.workspace }}/ml-backend
        run: |
          python scripts/validate_model_performance.py || echo "Model validation completed"
        continue-on-error: true

  # Job 7: Deploy to Render
  deploy:
    name: Deploy to Render
    runs-on: ubuntu-latest
    needs: [integration-test, build, security, model-validation]
    if: github.ref == 'refs/heads/main'
    steps:
      - uses: actions/checkout@v4
      
      - name: Deploy to Render
        env:
          RENDER_API_KEY: ${{ secrets.RENDER_API_KEY }}
          RENDER_SERVICE_ID: ${{ secrets.RENDER_BACKEND_SERVICE_ID }}
        run: |
          curl -X POST "https://api.render.com/v1/services/$RENDER_SERVICE_ID/deploys" \
            -H "Authorization: Bearer $RENDER_API_KEY" \
            -H "Content-Type: application/json" \
            -d '{"clearCache": false}'
      
      - name: Wait for deployment
        run: sleep 90
      
      - name: Smoke test production
        env:
          RENDER_SERVICE_URL: ${{ secrets.RENDER_BACKEND_URL }}
        run: |
          curl -f $RENDER_SERVICE_URL/health || exit 1
          curl -f $RENDER_SERVICE_URL/ || exit 1
          curl -f $RENDER_SERVICE_URL/metrics || echo "Metrics check"
          echo "âœ… Backend deployment successful!"

  # Job 8: Post-Deploy Monitoring
  monitor:
    name: Post-Deploy Monitoring
    runs-on: ubuntu-latest
    needs: deploy
    if: github.ref == 'refs/heads/main'
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: Check metrics endpoint
        env:
          RENDER_SERVICE_URL: ${{ secrets.RENDER_BACKEND_URL }}
        run: |
          curl -f $RENDER_SERVICE_URL/metrics || echo "Metrics endpoint not available"
      
      - name: Check API documentation
        env:
          RENDER_SERVICE_URL: ${{ secrets.RENDER_BACKEND_URL }}
        run: |
          curl -f $RENDER_SERVICE_URL/docs || echo "API docs check"
      
      - name: Deployment notification
        run: |
          echo "ðŸš€ Backend Deployment Complete!"
          echo "Service: ${{ secrets.RENDER_BACKEND_URL }}"
          echo "Commit: ${{ github.sha }}"
          echo "Branch: ${{ github.ref }}"
          echo "Deployed at: $(date)"